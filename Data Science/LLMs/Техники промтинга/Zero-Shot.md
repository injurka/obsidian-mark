Большие языковые модели (**LLMs**), такие как *GPT-3*, настроены на следование инструкциям и обучаются на больших объемах данных, поэтому они способны выполнять некоторые задачи "нулевой разметки".

*Запрос:*

```
Classify the text into neutral, negative or positive. 

Text: I think the vacation is okay.
Sentiment:
```

*Результат:*

```
Neutral
```

Тюнинг инструкций и применение *RLHF* (усиление обучения на основе обратной связи от человека) улучшают возможности нулевой разметки, позволяя модели лучше соответствовать предпочтениям людей.

Когда **Zero-Shot** промптинг неэффективен, рекомендуется использовать [[Few-Shot]] промптинг, предоставляя примеры в запросе.

## Источники
- #### [promptingguide](https://www.promptingguide.ai/ru/techniques/zeroshot)