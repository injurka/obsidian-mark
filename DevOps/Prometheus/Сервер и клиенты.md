## Scrape и подсчет метрик

В контексте описанной системы, где Prometheus собирает метрики с вашего приложения, обычно происходит следующее:

1. **Scraping**: Prometheus делает HTTP-запрос к вашему приложению по адресу `/metrics`.
    
2. **Ответ приложения**: Приложение возвращает текущие значения метрик в формате, понятном Prometheus (обычно это формат Prometheus Text).
    
3. **Сохранение в БД Prometheus**: Prometheus сохраняет эти метрики в свою базу данных с текущим timestamp.
    

**Важно**: При каждом запросе `/metrics`, Prometheus получает текущие значения метрик на момент запроса. Это означает, что он не сохраняет историю каждого изменения метрики между скрейпами, а только текущее состояние на момент скрейпа.

Таким образом, если за 30 секунд пришло 10 HTTP-запросов, и в этот момент произошел скрейп, Prometheus получит информацию о текущем количестве запросов (например, 10) и сохранит это значение с текущим timestamp. При следующем скрейпе он получит новое значение метрики, и так далее.

| Правильно                                      | Неправильно        |
| ---------------------------------------------- | ------------------ |
| Продолжаем дальше инкрементить этот же счетчик | Сбрасываем счетчик |

Да, технически счетчик можно сбросить, но делать этого не нужно! У приложения будет вечно копиться увеличивающийся счетчик (**монотонно возрастающий**). Это свойство нам пригодится потом: грубо говоря, чтобы узнать, «сколько пришло запросов _за последнюю минуту_», Prometheus будет брать производную. Кстати, производные — это не страшно: подробное и понятное объяснение будет в одной из следующих частей.

## Безопасность

Prometheus по умолчанию приходит за метриками без аутентификации. Возникает проблема: а как закрыть к ним доступ, чтобы нельзя было что-то подсмотреть? Это особенно важно, если приложение доступно снаружи, из интернета. Есть разные варианты, кому как удобнее:

- Настроить аутентификацию в самом Prometheus: он будет присылать запросы с нужными вам заголовками.
    
- Хостить endpoint `/metrics` на отдельном порту, который не выставлен наружу.
    
- Настроить файерволл.
    
- Сделать whitelist на уровне приложения.
    

## Альтернативные способы скрапинга

Не всегда код живет как приложение с HTTP-сервером. Бывает, что это сервис без HTTP, какой-нибудь обработчик очередей RabbitMQ или вообще cronjob, который запускается по таймеру, отрабатывает и умирает.

Простой способ собрать метрики в таких случаях – решить, что накладные расходы на добавление HTTP-сервера только ради `/metrics` вас не пугают. Это нормально, но не поможет cronjob-ам, которые не живут как постоянный процесс и не могут хранить и отдавать метрики каждые 30 секунд. Поэтому есть варианты, как можно обустроить сбор метрик в обход pull-модели. Придется поднять вспомогательный сервис на выбор:

- [Pushgateway](https://prometheus.io/docs/practices/pushing/) – компонент Prometheus, который, по сути, живет как промежуточное приложение: в него можно отправить свои метрики, а Pushgateway уже будет их раздавать Prometheus’у.
    
- [Telegraf](https://github.com/influxdata/telegraf) – универсальный конвертер и агрегатор метрик, который тоже придется держать постоянно запущенным. Можно настроить его на сбор и получение метрик любым удобным способом. Он умеет фильтровать и конвертировать полученные данные, а результат с него уже заберет Prometheus.
    
- [StatsD Exporter](https://github.com/prometheus/statsd_exporter) – приложение должно отправить туда метрики в формате **statsd**, а он их выставит для Prometheus. Концептуальное отличие только в формате, его точно так же придется держать постоянно запущенным.
    

Со стороны нашего кода обычно нужно подключить и настроить библиотеку для сбора метрик. Она уже будет агрегировать, форматировать и отдавать страницу с метриками. В каком-то стеке библиотеки сами подружатся с вашим веб-сервером, где-то придется поколдовать. Основная идея в том, что библиотеки для работы с метриками предоставляют API, через которое нужно зарегистрировать и описать метрику, и потом ее обновлять из любого места в приложении. Например, при получении HTTP-запроса увеличиваем метрику «количество запросов на этот endpoint», при отправке ответа – увеличиваем метрику «время обработки запросов». Теперь пора разобраться с тем, что такое метрики с точки зрения Prometheus, и как они обновляются из кода. Так мы поймем, какие методы использовать и какие метрики лучше подходят для определенных задач.

## Prometheus – формат данных

Формат, в котором метрики пишутся приложением и отдаются Prometheus-ом из БД, достаточно простой и сделан, чтобы легко читаться глазами. Подсчет и форматирование метрик из приложения не нужно делать вручную — для этого есть библиотеки. Вот так выглядит страничка, которую приложение должно отдать на `GET /metrics`:

```q
# HELP http_requests_total Requests made to public API# TYPE http_requests_total counterhttp_requests_total{method="POST", url="/messages"} 1http_requests_total{method="GET", url="/messages"} 3http_requests_total{method="POST", url="/login"} 2
```

Что здесь есть:

- `HELP` — описание для помощи человекам;
    
- `TYPE` — тип метрики;
    
- `http_requests_total` — имя метрики;
    
- набор key-value лейблов (можно еще называть их тегами);
    
- значение метрики (64-bit float aka double);
    
- после сбора в БД добавляется еще timestamp.
    

Хранение работает так: имя метрики – на самом деле тоже лейбл с именем `__name__`. Все лейблы вместе описывают собой time series (временной ряд), т.е. это как бы **имя таблицы**, составленное из всех key-value. В этом ряду лежат значения `[(timestamp1, double1), (timestamp2, double2), ...]`. Из примера выше, у нас одна метрика, но в базе есть три таблицы: для `GET /messages`, `POST /messages` и `POST /login`. В каждую таблицу раз в 30 секунд пишется очередное число, которое момент scrape-а показало приложение.

> Хранятся double-ы в разрезе времени. Никаких int-ов. Никаких строк. Никакой дополнительной инфы. Только числа!

Кстати, полезно посмотреть [практики именования](https://prometheus.io/docs/practices/naming/) в документации. Лейблы используются для поиска и для агрегации, но есть одна особенность: серверу поплохеет, если для лейблов часто использовать **уникальные или редко повторяющиеся значения**. Потому что...

### Кардинальность

Каждое новое значение лейбла – это уже новый временной ряд. То есть новая таблица. Поэтому не надо ими злоупотреблять. Хороший лейбл ограничен в возможных значениях. То есть целиком `User-Agent` туда писать плохо, а вот название и мажорную версию браузера – ОК. Юзернейм, если их сотни – сомнительно, а если их десятки – ОК (api-клиенты внутреннего сервиса, например).

Например, мы пишем метрики о HTTP-запросах. Перемножаем все возможные значения всех лейблов: 2 HTTP глагола, 7 урлов, 5 реплик сервиса, 3 вида ответов (2xx, 3xx, 4xx), 4 браузера. **840** временных рядов! Ну то есть это как 840 таблиц в sql. Prometheus справляется с десятками миллионов рядов, но комбинаторный взрыв можно устроить очень быстро. Подробнее можно еще почитать тут: [Cardinality is key](https://www.robustperception.io/cardinality-is-key).

> В целом, не стесняясь пишите то, что вам действительно надо, но не злодействуйте. Следите за потреблением ресурсов Prometheus и чтобы в лейблах не было произвольного текста.

Прежде чем писать метрику, подумайте, в каком виде она будет отображаться? Вряд ли вам нужен график, на котором пляшут десятки разноцветных линий, поэтому записывать точный user-agent бесполезно. Вы все равно захотите его сгруппировать во что-то осмысленное. С другой стороны, одна и та же метрика может быть сгруппирована по разным лейблам и нарисована на разных графиках. Если вы, например, считаете HTTP-запросы и сохраняете в лейблы method, id клиента и код ответа, эту метрику уже можно вывести разными способами: `HTTP requests by client`, `HTTP requests by method and response code`.

## Источники
- #### [habr](https://habr.com/ru/companies/tochka/articles/685636/)
